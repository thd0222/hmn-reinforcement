{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dqn_breakout_deploy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thd0222/hmn-reinforcement/blob/master/dqn_breakout_deploy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0kV3fK6sxU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjNgjul0VyEM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "af122ccb-c66f-46d1-f486-9c8b12c50f19"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoXmeBKHsUQ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5d828474-7dcd-42d2-d7bd-fc4765e634aa"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import gym\n",
        "\n",
        "from collections import deque\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.losses import huber_loss\n",
        "from tensorboardcolab import *\n",
        "\n",
        "from gym import envs\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gze8t1QWtahw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6e8b968-98fb-47b5-bbee-492ffa1b3661"
      },
      "source": [
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay\n",
        "\n",
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 496 kB of archives.\n",
            "After this operation, 5,416 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Fetched 496 kB in 0s (5,978 kB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,266 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.4 [784 kB]\n",
            "Fetched 784 kB in 0s (8,811 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 146842 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.4_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/8a/643043cc70791367bee2d19eb20e00ed1a246ac48e5dbe57bbbcc8be40a9/PyVirtualDisplay-1.3.2-py2.py3-none-any.whl\n",
            "Collecting EasyProcess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.3 pyvirtualdisplay-1.3.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7fd334ffddd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT_SbbFT2fRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GAME = \"Breakout-v4\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkS7YkbOvzzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def ipython_show_video(path):\n",
        "    \"\"\"Show a video at `path` within IPython Notebook\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(path):\n",
        "        raise NameError(\"Cannot access: {}\".format(path))\n",
        "\n",
        "    video = io.open(path, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "\n",
        "    display(HTML(\n",
        "        data=\"\"\"\n",
        "        <video alt=\"test\" controls>\n",
        "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "        </video>\n",
        "        \"\"\".format(encoded.decode('ascii'))\n",
        "    ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sOrzSI_qdLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "base_path = '/your_path'\n",
        "\n",
        "datetime_path = datetime.now().strftime('%Y-%m-%d_%H:%M:%S')\n",
        "\n",
        "model_path = os.path.join(base_path, 'save_model', datetime_path)\n",
        "\n",
        "os.makedirs(model_path, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uweIXwzfgZm",
        "colab_type": "text"
      },
      "source": [
        "### 학습 속도를 높이기 위해 흑백 화면으로 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPKuMtqaupLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 210*160*3(color) --> 84*84(mono)\n",
        "# float --> integer (to reduce the size of replay memory)\n",
        "def pre_processing(observe):\n",
        "    processed_observe = np.uint8(\n",
        "        resize(rgb2gray(observe), (84, 84), mode='constant') * 255)\n",
        "    return processed_observe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBRF3oDsmai6",
        "colab_type": "text"
      },
      "source": [
        "### Agent 클래스 정의\n",
        "* 하이퍼파라미터  \n",
        "  * epsilon : 탐색을 위한 확률정보 값\n",
        "  * epsilon_start, self.epsilon_end : 입실론 값의 범위 \n",
        "  * exploration_steps : 입실론 값을 감소시킬 단계\n",
        "  * epsilon_decay_step : 한번에 감소시킬 입실론 크기\n",
        "  * batch_size : 배치 사이즈\n",
        "  * train_start : 학습 시작 메모리 길이\n",
        "  * update_target_rate : 타겟 네트워크를 업데이트 시킬 step\n",
        "  * discount_factor : 감가율\n",
        "  * memory : 학습정보를 담기위한 메모리 객체\n",
        "  * no_op_steps : 30 스텝 이후 학습정보를 모으기 위한 설정값\n",
        "* 함수\n",
        "  * optimizer(self) : Huber Loss를 이용한 최적화 함수 정의\n",
        "  * build_model(self) : 상태가 입력, 큐함수가 출력인 모델 생성\n",
        "  * update_target_model(self) : 타겟 모델을 모델의 가중치로 업데이트\n",
        "  * get_action(self, history) : 입실론 탐욕 정책으로 행동 선택\n",
        "  * remember(self, history, action, reward, next_history, dead) : 샘플 <s,a,r,s'>을 리플레이 메모리에 저장\n",
        "  * train_replay(self) : 리플레이 메모리에서 무작위로 추출한 배치로 모델 학습\n",
        "  * save_model(self, name): 학습 모델 저장\n",
        "  * load_model(self, filename): 학습 모델 로드\n",
        "  * setup_summary(self): 각 에피소드당 학습 정보를 기록"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9RoSWl9vCyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, action_size, model_load=False):\n",
        "        self.render = False\n",
        "        self.load_model = False\n",
        "        # 상태와 행동의 크기 정의\n",
        "        self.state_size = (84, 84, 4)\n",
        "        self.action_size = action_size\n",
        "        # DQN 하이퍼파라미터 정의\n",
        "        self.epsilon = 1.\n",
        "        self.epsilon_start, self.epsilon_end = 1.0, 0.1\n",
        "        self.exploration_steps = 10.\n",
        "        self.epsilon_decay_step = (self.epsilon_start - self.epsilon_end) \\\n",
        "                                  / self.exploration_steps\n",
        "        # 학습을 위한 파라미터 정의\n",
        "        self.batch_size = 32\n",
        "        self.train_start = 50000\n",
        "        self.update_target_rate = 10000\n",
        "        self.discount_factor = 0.99\n",
        "        self.memory = deque(maxlen=400000)\n",
        "        self.no_op_steps = 30\n",
        "\n",
        "        # 모델과 타겟 모델을 생성하고 타겟 모델을 초기화\n",
        "        self.model = self.build_model()\n",
        "        self.target_model = self.build_model()\n",
        "        self.update_target_model()\n",
        "\n",
        "        self.optimizer = self.optimizer()\n",
        "\n",
        "        self.sess = tf.InteractiveSession()\n",
        "        K.set_session(self.sess)\n",
        "\n",
        "        self.avg_q_max, self.avg_loss = 0, 0\n",
        "        self.summary_placeholders, self.update_ops, self.summary_op = \\\n",
        "            self.setup_summary()\n",
        "        \n",
        "        tbc=TensorBoardColab()\n",
        "        \n",
        "        self.summary_writer = tbc.get_writer()\n",
        "        self.summary_writer = tf.summary.FileWriter(\n",
        "            './Graph', self.sess.graph)\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        if self.load_model:\n",
        "            self.model.load_weights(os.path.join(model_path, \"breakout_dqn.h5\"))\n",
        "\n",
        "    # Huber Loss를 이용한 최적화 함수 정의\n",
        "    def optimizer(self):\n",
        "\n",
        "        return train\n",
        "\n",
        "    # 상태가 입력, 큐함수가 출력인 모델 생성\n",
        "    def build_model(self):\n",
        "\n",
        "        return model\n",
        "\n",
        "    # 타겟 모델을 모델의 가중치로 업데이트\n",
        "    def update_target_model(self):\n",
        "        \n",
        "\n",
        "    # 입실론 탐욕 정책으로 행동 선택\n",
        "    def get_action(self, history):\n",
        "\n",
        "\n",
        "    # 샘플 <s,a,r,s'>을 리플레이 메모리에 저장\n",
        "    def remember(self, history, action, reward, next_history, dead):\n",
        "\n",
        "\n",
        "    # 리플레이 메모리에서 무작위로 추출한 배치로 모델 학습\n",
        "    def train_replay(self):\n",
        "        if len(self.memory) < self.train_start:\n",
        "            return\n",
        "        if self.epsilon > self.epsilon_end:\n",
        "            self.epsilon -= self.epsilon_decay_step\n",
        "\n",
        "        mini_batch = random.sample(self.memory, self.batch_size)\n",
        "\n",
        "        history = np.zeros((self.batch_size, self.state_size[0],\n",
        "                            self.state_size[1], self.state_size[2]))\n",
        "        next_history = np.zeros((self.batch_size, self.state_size[0],\n",
        "                                 self.state_size[1], self.state_size[2]))\n",
        "        target = np.zeros((self.batch_size,))\n",
        "        action, reward, dead = [], [], []\n",
        "\n",
        "        # replay 메모리에 담겨 있는 데이터 분할\n",
        "        for i in range(self.batch_size):\n",
        "\n",
        "        # 타겟 모델에서 Q-value 계산\n",
        "        target_value = self.target_model.predict(next_history)\n",
        "\n",
        "        # 타겟 모델에서 s' 상태에서의 최대 Q 함수 값을 가져옴\n",
        "        for i in range(self.batch_size):\n",
        "            if dead[i]:\n",
        "                target[i] = reward[i]\n",
        "            else:\n",
        "                target[i] = reward[i] \\\n",
        "                            + self.discount_factor * np.amax(target_value[i])\n",
        "\n",
        "        # self.optimizer 함수를 통해 모델 업데이트\n",
        "\n",
        "\n",
        "    def save_model(self, name):\n",
        "        self.model.save_weights(name)\n",
        "    \n",
        "    def load_model(self, filename):\n",
        "        self.model.load_weights(filename)\n",
        "\n",
        "    # 각 에피소드당 학습 정보를 기록\n",
        "    def setup_summary(self):\n",
        "        episode_total_reward = tf.Variable(0.)\n",
        "        episode_avg_max_q = tf.Variable(0.)\n",
        "        episode_duration = tf.Variable(0.)\n",
        "        episode_avg_loss = tf.Variable(0.)\n",
        "\n",
        "        tf.summary.scalar('Total_Reward/Episode', episode_total_reward)\n",
        "        tf.summary.scalar('Average_Max_Q/Episode', episode_avg_max_q)\n",
        "        tf.summary.scalar('Duration/Episode', episode_duration)\n",
        "        tf.summary.scalar('Average_Loss/Episode', episode_avg_loss)\n",
        "\n",
        "        summary_vars = [episode_total_reward, episode_avg_max_q,\n",
        "                        episode_duration, episode_avg_loss]\n",
        "        summary_placeholders = [tf.placeholder(tf.float32) for _ in\n",
        "                                range(len(summary_vars))]\n",
        "        update_ops = [summary_vars[i].assign(summary_placeholders[i]) for i in\n",
        "                      range(len(summary_vars))]\n",
        "        summary_op = tf.summary.merge_all()\n",
        "        return summary_placeholders, update_ops, summary_op"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJKHy75Uzkhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPISODES = 50000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWRLX2kVvKin",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bdccd926-24a5-425d-9706-600a9cec783a"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    from gym import wrappers\n",
        "    \n",
        "    # breakout 게임 환경 생성\n",
        "    env = gym.make('BreakoutDeterministic-v4')\n",
        "\n",
        "    # colab(모니터가 없는 서버)에서 게임 시행을 위한 모니터 래퍼 추가\n",
        "    env = wrappers.Monitor(env, f\"/tmp/{GAME}\", force=True)\n",
        "    \n",
        "    # DQN agent 객체 생성\n",
        "    agent = DQNAgent(action_size=3)\n",
        "\n",
        "    scores, episodes, global_step = [], [], 0\n",
        "\n",
        "    for e in range(EPISODES):\n",
        "        done = False\n",
        "        dead = False\n",
        "        \n",
        "        # 1 episode = 5 lives\n",
        "        step, score, start_life = 0, 0, 5\n",
        "        observe = env.reset()\n",
        "\n",
        "        # 30 no-op(30 타임세텝 동안 에이전트는 정지)\n",
        "        for _ in range(random.randint(1, agent.no_op_steps)):\n",
        "            observe, _, _, _ = env.step(1)\n",
        "\n",
        "        # 에피소드 시작시 이전 프레임이 없으므로\n",
        "        # 초기 상태를 복사하여 기록 생성\n",
        "\n",
        "        while not done:\n",
        "            if agent.render:\n",
        "                env.render()\n",
        "            global_step += 1\n",
        "            step += 1\n",
        "\n",
        "            # 바로 전 4개의 상태로 행동을 선택\n",
        "            \n",
        "            # 1: 정지/ 2: 왼쪽/ 3: 오른쪽\n",
        "            if action == 0:\n",
        "                real_action = 1\n",
        "            elif action == 1:\n",
        "                real_action = 2\n",
        "            else:\n",
        "                real_action = 3\n",
        "\n",
        "            # 선택한 행동으로 환경에서 한 타임스텝 진행\n",
        "            \n",
        "\n",
        "            # 매 스텝 마다 관찰된 상태(이미지) 전처리\n",
        "\n",
        "\n",
        "            # 에이전트가 공을 놓치면 dead --> 에피소드는 종료되지 않음\n",
        "\n",
        "\n",
        "            # 샘플 <s, a, r, s'>을 리플레이 메모리에 저장 후 학습\n",
        "\n",
        "            \n",
        "            # 일정 시간마다 타깃 모델을 모델의 가중치로 업데이트\n",
        "\n",
        "\n",
        "            # 에이전트가 dead 면, dead 값 리셋\n",
        "            if dead:\n",
        "                dead = False\n",
        "            else:\n",
        "                history = next_history\n",
        "\n",
        "            # 각 에피스드 마다 학습 정보를 기록\n",
        "            if done:\n",
        "                if global_step > agent.train_start:\n",
        "                    stats = [score, agent.avg_q_max / float(step), step,\n",
        "                             agent.avg_loss / float(step)]\n",
        "                    for i in range(len(stats)):\n",
        "                        agent.sess.run(agent.update_ops[i], feed_dict={\n",
        "                            agent.summary_placeholders[i]: float(stats[i])\n",
        "                        })\n",
        "                    summary_str = agent.sess.run(agent.summary_op)\n",
        "                    agent.summary_writer.add_summary(summary_str, e + 1)\n",
        "\n",
        "                print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
        "                      len(agent.memory), \"  epsilon:\", agent.epsilon,\n",
        "                      \"  global_step:\", global_step, \"  average_q:\",\n",
        "                      agent.avg_q_max / float(step), \"  average loss:\",\n",
        "                      agent.avg_loss / float(step))\n",
        "\n",
        "                agent.avg_q_max, agent.avg_loss = 0, 0\n",
        "\n",
        "        # 1000 에피소드마다 모델 저장\n",
        "        if e % 100 == 0:\n",
        "            agent.model.save_weights(os.path.join(model_path, \"breakout_dqn.h5\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 20, 20, 32)        8224      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 9, 9, 64)          32832     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1606144   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 1,685,667\n",
            "Trainable params: 1,685,667\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 20, 20, 32)        8224      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 9, 9, 64)          32832     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               1606144   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 1,685,667\n",
            "Trainable params: 1,685,667\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "http://ed3936a96343.ngrok.io\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorboardcolab/core.py:49: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "episode: 0   score: 0.0   memory length: 119   epsilon: 1.0   global_step: 119   average_q: 0.04250946180785403   average loss: 0.0\n",
            "episode: 1   score: 1.0   memory length: 301   epsilon: 1.0   global_step: 301   average_q: 0.04122612258972048   average loss: 0.0\n",
            "episode: 2   score: 2.0   memory length: 491   epsilon: 1.0   global_step: 491   average_q: 0.04106134637013862   average loss: 0.0\n",
            "episode: 3   score: 0.0   memory length: 620   epsilon: 1.0   global_step: 620   average_q: 0.04261699246690255   average loss: 0.0\n",
            "episode: 4   score: 0.0   memory length: 720   epsilon: 1.0   global_step: 720   average_q: 0.042566377967596054   average loss: 0.0\n",
            "episode: 5   score: 2.0   memory length: 906   epsilon: 1.0   global_step: 906   average_q: 0.041602900772485685   average loss: 0.0\n",
            "episode: 6   score: 0.0   memory length: 1024   epsilon: 1.0   global_step: 1024   average_q: 0.04298098319036476   average loss: 0.0\n",
            "episode: 7   score: 0.0   memory length: 1141   epsilon: 1.0   global_step: 1141   average_q: 0.04257638153866825   average loss: 0.0\n",
            "episode: 8   score: 1.0   memory length: 1311   epsilon: 1.0   global_step: 1311   average_q: 0.04174334299476708   average loss: 0.0\n",
            "episode: 9   score: 0.0   memory length: 1420   epsilon: 1.0   global_step: 1420   average_q: 0.042517905080810596   average loss: 0.0\n",
            "episode: 10   score: 0.0   memory length: 1529   epsilon: 1.0   global_step: 1529   average_q: 0.04253528144108046   average loss: 0.0\n",
            "episode: 11   score: 0.0   memory length: 1639   epsilon: 1.0   global_step: 1639   average_q: 0.04256565012037754   average loss: 0.0\n",
            "episode: 12   score: 2.0   memory length: 1814   epsilon: 1.0   global_step: 1814   average_q: 0.041611498360122956   average loss: 0.0\n",
            "episode: 13   score: 0.0   memory length: 1920   epsilon: 1.0   global_step: 1920   average_q: 0.04343736860549675   average loss: 0.0\n",
            "episode: 14   score: 2.0   memory length: 2099   epsilon: 1.0   global_step: 2099   average_q: 0.040936655942454686   average loss: 0.0\n",
            "episode: 15   score: 3.0   memory length: 2361   epsilon: 1.0   global_step: 2361   average_q: 0.04156383165364502   average loss: 0.0\n",
            "episode: 16   score: 1.0   memory length: 2515   epsilon: 1.0   global_step: 2515   average_q: 0.042003896329310036   average loss: 0.0\n",
            "episode: 17   score: 1.0   memory length: 2665   epsilon: 1.0   global_step: 2665   average_q: 0.040968893592556316   average loss: 0.0\n",
            "episode: 18   score: 1.0   memory length: 2822   epsilon: 1.0   global_step: 2822   average_q: 0.04043851538923136   average loss: 0.0\n",
            "episode: 19   score: 0.0   memory length: 2940   epsilon: 1.0   global_step: 2940   average_q: 0.04252445833536528   average loss: 0.0\n",
            "episode: 20   score: 1.0   memory length: 3096   epsilon: 1.0   global_step: 3096   average_q: 0.04228886773284429   average loss: 0.0\n",
            "episode: 21   score: 0.0   memory length: 3224   epsilon: 1.0   global_step: 3224   average_q: 0.04267456606612541   average loss: 0.0\n",
            "episode: 22   score: 1.0   memory length: 3365   epsilon: 1.0   global_step: 3365   average_q: 0.042430392605193115   average loss: 0.0\n",
            "episode: 23   score: 1.0   memory length: 3505   epsilon: 1.0   global_step: 3505   average_q: 0.04230936736400638   average loss: 0.0\n",
            "episode: 24   score: 0.0   memory length: 3629   epsilon: 1.0   global_step: 3629   average_q: 0.04265839080776899   average loss: 0.0\n",
            "episode: 25   score: 2.0   memory length: 3827   epsilon: 1.0   global_step: 3827   average_q: 0.042293992664928386   average loss: 0.0\n",
            "episode: 26   score: 0.0   memory length: 3931   epsilon: 1.0   global_step: 3931   average_q: 0.0431059066277857   average loss: 0.0\n",
            "episode: 27   score: 2.0   memory length: 4119   epsilon: 1.0   global_step: 4119   average_q: 0.04228698184832613   average loss: 0.0\n",
            "episode: 28   score: 1.0   memory length: 4256   epsilon: 1.0   global_step: 4256   average_q: 0.04276244867130788   average loss: 0.0\n",
            "episode: 29   score: 2.0   memory length: 4445   epsilon: 1.0   global_step: 4445   average_q: 0.04123118417288261   average loss: 0.0\n",
            "episode: 30   score: 0.0   memory length: 4553   epsilon: 1.0   global_step: 4553   average_q: 0.0431847444700974   average loss: 0.0\n",
            "episode: 31   score: 0.0   memory length: 4684   epsilon: 1.0   global_step: 4684   average_q: 0.04258627117476391   average loss: 0.0\n",
            "episode: 32   score: 2.0   memory length: 4884   epsilon: 1.0   global_step: 4884   average_q: 0.041067298501729965   average loss: 0.0\n",
            "episode: 33   score: 2.0   memory length: 5121   epsilon: 1.0   global_step: 5121   average_q: 0.04269270243649744   average loss: 0.0\n",
            "episode: 34   score: 2.0   memory length: 5328   epsilon: 1.0   global_step: 5328   average_q: 0.04256134868963905   average loss: 0.0\n",
            "episode: 35   score: 0.0   memory length: 5454   epsilon: 1.0   global_step: 5454   average_q: 0.04273888498308167   average loss: 0.0\n",
            "episode: 36   score: 3.0   memory length: 5678   epsilon: 1.0   global_step: 5678   average_q: 0.03994437468437744   average loss: 0.0\n",
            "episode: 37   score: 0.0   memory length: 5787   epsilon: 1.0   global_step: 5787   average_q: 0.042733779091627226   average loss: 0.0\n",
            "episode: 38   score: 5.0   memory length: 6117   epsilon: 1.0   global_step: 6117   average_q: 0.04011116701770912   average loss: 0.0\n",
            "episode: 39   score: 1.0   memory length: 6273   epsilon: 1.0   global_step: 6273   average_q: 0.041750540097172446   average loss: 0.0\n",
            "episode: 40   score: 0.0   memory length: 6398   epsilon: 1.0   global_step: 6398   average_q: 0.04330337336659432   average loss: 0.0\n",
            "episode: 41   score: 2.0   memory length: 6582   epsilon: 1.0   global_step: 6582   average_q: 0.04250125912949443   average loss: 0.0\n",
            "episode: 42   score: 0.0   memory length: 6685   epsilon: 1.0   global_step: 6685   average_q: 0.043552906876339496   average loss: 0.0\n",
            "episode: 43   score: 0.0   memory length: 6783   epsilon: 1.0   global_step: 6783   average_q: 0.04227560370856402   average loss: 0.0\n",
            "episode: 44   score: 2.0   memory length: 6999   epsilon: 1.0   global_step: 6999   average_q: 0.04023769128791712   average loss: 0.0\n",
            "episode: 45   score: 1.0   memory length: 7152   epsilon: 1.0   global_step: 7152   average_q: 0.03823680985792011   average loss: 0.0\n",
            "episode: 46   score: 1.0   memory length: 7314   epsilon: 1.0   global_step: 7314   average_q: 0.040421222509057435   average loss: 0.0\n",
            "episode: 47   score: 0.0   memory length: 7436   epsilon: 1.0   global_step: 7436   average_q: 0.04256693267675697   average loss: 0.0\n",
            "episode: 48   score: 1.0   memory length: 7588   epsilon: 1.0   global_step: 7588   average_q: 0.04179356680986913   average loss: 0.0\n",
            "episode: 49   score: 3.0   memory length: 7824   epsilon: 1.0   global_step: 7824   average_q: 0.04093273408647816   average loss: 0.0\n",
            "episode: 50   score: 3.0   memory length: 8058   epsilon: 1.0   global_step: 8058   average_q: 0.04189865943840426   average loss: 0.0\n",
            "episode: 51   score: 2.0   memory length: 8259   epsilon: 1.0   global_step: 8259   average_q: 0.04061071611755523   average loss: 0.0\n",
            "episode: 52   score: 2.0   memory length: 8451   epsilon: 1.0   global_step: 8451   average_q: 0.042709369057168566   average loss: 0.0\n",
            "episode: 53   score: 4.0   memory length: 8735   epsilon: 1.0   global_step: 8735   average_q: 0.04100114356359126   average loss: 0.0\n",
            "episode: 54   score: 1.0   memory length: 8886   epsilon: 1.0   global_step: 8886   average_q: 0.041703757490740706   average loss: 0.0\n",
            "episode: 55   score: 0.0   memory length: 9019   epsilon: 1.0   global_step: 9019   average_q: 0.04294078657053467   average loss: 0.0\n",
            "episode: 56   score: 3.0   memory length: 9239   epsilon: 1.0   global_step: 9239   average_q: 0.04192892468788407   average loss: 0.0\n",
            "episode: 57   score: 2.0   memory length: 9416   epsilon: 1.0   global_step: 9416   average_q: 0.040640177868180354   average loss: 0.0\n",
            "episode: 58   score: 1.0   memory length: 9581   epsilon: 1.0   global_step: 9581   average_q: 0.04220113995851892   average loss: 0.0\n",
            "episode: 59   score: 0.0   memory length: 9699   epsilon: 1.0   global_step: 9699   average_q: 0.04267576065356449   average loss: 0.0\n",
            "episode: 60   score: 1.0   memory length: 9867   epsilon: 1.0   global_step: 9867   average_q: 0.04032548268636068   average loss: 0.0\n",
            "episode: 61   score: 2.0   memory length: 10044   epsilon: 1.0   global_step: 10044   average_q: 0.04184973837628876   average loss: 0.0\n",
            "episode: 62   score: 2.0   memory length: 10222   epsilon: 1.0   global_step: 10222   average_q: 0.04345156229362729   average loss: 0.0\n",
            "episode: 63   score: 0.0   memory length: 10330   epsilon: 1.0   global_step: 10330   average_q: 0.04298435065343424   average loss: 0.0\n",
            "episode: 64   score: 2.0   memory length: 10513   epsilon: 1.0   global_step: 10513   average_q: 0.04234147896287871   average loss: 0.0\n",
            "episode: 65   score: 0.0   memory length: 10632   epsilon: 1.0   global_step: 10632   average_q: 0.04269909839920637   average loss: 0.0\n",
            "episode: 66   score: 1.0   memory length: 10788   epsilon: 1.0   global_step: 10788   average_q: 0.041985136026946396   average loss: 0.0\n",
            "episode: 67   score: 1.0   memory length: 10927   epsilon: 1.0   global_step: 10927   average_q: 0.04310256416956298   average loss: 0.0\n",
            "episode: 68   score: 3.0   memory length: 11199   epsilon: 1.0   global_step: 11199   average_q: 0.040966689723598605   average loss: 0.0\n",
            "episode: 69   score: 2.0   memory length: 11388   epsilon: 1.0   global_step: 11388   average_q: 0.04291021798259367   average loss: 0.0\n",
            "episode: 70   score: 2.0   memory length: 11561   epsilon: 1.0   global_step: 11561   average_q: 0.03999405759090633   average loss: 0.0\n",
            "episode: 71   score: 4.0   memory length: 11834   epsilon: 1.0   global_step: 11834   average_q: 0.04446636477396602   average loss: 0.0\n",
            "episode: 72   score: 0.0   memory length: 11938   epsilon: 1.0   global_step: 11938   average_q: 0.0436860195790919   average loss: 0.0\n",
            "episode: 73   score: 0.0   memory length: 12060   epsilon: 1.0   global_step: 12060   average_q: 0.04231608924684954   average loss: 0.0\n",
            "episode: 74   score: 0.0   memory length: 12185   epsilon: 1.0   global_step: 12185   average_q: 0.04248056608438492   average loss: 0.0\n",
            "episode: 75   score: 0.0   memory length: 12296   epsilon: 1.0   global_step: 12296   average_q: 0.042682582999134924   average loss: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwfi__sWvMdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestAgent:\n",
        "    def __init__(self, action_size):\n",
        "        self.state_size = (84, 84, 4)\n",
        "        self.action_size = action_size\n",
        "        self.no_op_steps = 20\n",
        "\n",
        "        self.model = self.build_model()\n",
        "\n",
        "        self.sess = tf.InteractiveSession()\n",
        "        K.set_session(self.sess)\n",
        "\n",
        "        self.avg_q_max, self.avg_loss = 0, 0\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    def build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(32, (8, 8), strides=(4, 4), activation='relu',\n",
        "                         input_shape=self.state_size))\n",
        "        model.add(Conv2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
        "        model.add(Conv2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(512, activation='relu'))\n",
        "        model.add(Dense(self.action_size))\n",
        "        model.summary()\n",
        "\n",
        "        return model\n",
        "\n",
        "    def get_action(self, history):\n",
        "        if np.random.random() < 0.01:\n",
        "            return random.randrange(3)\n",
        "        history = np.float32(history / 255.0)\n",
        "        q_value = self.model.predict(history)\n",
        "        return np.argmax(q_value[0])\n",
        "\n",
        "    def load_model(self, filename):\n",
        "        self.model.load_weights(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNaYYaxIvrRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_EPISODES = 10\n",
        "model_to_load = os.path.join(model_path, 'breakout_dqn.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zhRFRSnL8Jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_EPISODES = 10\n",
        "link = \"https://drive.google.com/open?id=1RbNmbp8EBXDom3MhhoWezdLNxY3xGPHL\"\n",
        "fluff, id = link.split('=')\n",
        "gdd.download_file_from_google_drive(file_id=id,\n",
        "                                    dest_path='./model_trained.h5')\n",
        "model_to_load = 'model_trained.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLnkOyASM1IR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c6dbdd68-c1df-4a9d-8eaf-e24c1a5fdfac"
      },
      "source": [
        "model_to_load"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model_trained.h5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GtqWr3kvPvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    from gym import wrappers\n",
        "    \n",
        "    # add virtual monitor for capturing video\n",
        "    env = gym.make('BreakoutDeterministic-v4')\n",
        "    env = wrappers.Monitor(env, f\"/tmp/BreakoutDeterministic-v4\", force=True)\n",
        "  \n",
        "    agent = TestAgent(action_size=3)\n",
        "    agent.load_model(model_to_load)\n",
        "\n",
        "    for e in range(TEST_EPISODES):\n",
        "        done = False\n",
        "        dead = False\n",
        "       \n",
        "        step, score, start_life = 0, 0, 5\n",
        "        observe = env.reset()\n",
        "\n",
        "        for _ in range(random.randint(1, agent.no_op_steps)):\n",
        "            observe, _, _, _ = env.step(1)\n",
        "\n",
        "        state = pre_processing(observe)\n",
        "        history = np.stack((state, state, state, state), axis=2)\n",
        "        history = np.reshape([history], (1, 84, 84, 4))\n",
        "\n",
        "        while not done:\n",
        "            env.render()\n",
        "            step += 1\n",
        "\n",
        "            action = agent.get_action(history)\n",
        "\n",
        "            if action == 0:\n",
        "                real_action = 1\n",
        "            elif action == 1:\n",
        "                real_action = 2\n",
        "            else:\n",
        "                real_action = 3\n",
        "\n",
        "            if dead:\n",
        "                real_action = 1\n",
        "                dead = False\n",
        "\n",
        "            observe, reward, done, info = env.step(real_action)\n",
        "\n",
        "            next_state = pre_processing(observe)\n",
        "            next_state = np.reshape([next_state], (1, 84, 84, 1))\n",
        "            next_history = np.append(next_state, history[:, :, :, :3], axis=3)\n",
        "\n",
        "            if start_life > info['ale.lives']:\n",
        "                dead = True\n",
        "                start_life = info['ale.lives']\n",
        "\n",
        "            score += reward\n",
        " \n",
        "            history = next_history\n",
        "\n",
        "            if done:\n",
        "                print(\"episode:\", e, \"  score:\", score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIItIH4czFF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /tmp/BreakoutDeterministic-v4 -al"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvhadlO-zLpt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "b3348337-968c-432b-ef73-3afb4e7b9dca"
      },
      "source": [
        "ipython_show_video(\"/tmp/BreakoutDeterministic-v4/openaigym.video.1.1084.video000008.mp4\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <video alt=\"test\" controls>\n",
              "        <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "        </video>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkGvDIqY0hYc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ebe71d7f-6484-42be-b806-ded1b1b13e54"
      },
      "source": [
        "agent.epsilon, agent.epsilon_decay_step, agent.epsilon_end"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 0.09, 0.1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7MhZv-C1rzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}